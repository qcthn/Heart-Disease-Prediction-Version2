# -*- coding: utf-8 -*-
"""Chuandoanbenhtim-DataMining.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RcCYobjKTD_mWd0ZHA6QbOKscJIn118E

# Import các thư viện cần thiết
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/DecisionSupportSystem-V2/Heart Disease.xlsx')
df.head()

"""## Kiểm tra dữ liệu có đủ yêu cầu không


1.   Số thuộc tính, số dòng
2.   Thông tin về các thuộc tính

-> Dữ liệu bao gồm 18 trường dữ liệu, 319795 dòng


"""

df.shape

df.info()

df.isnull().sum()

df.duplicated()

# Tạo một biểu đồ heatmap, mối quan hệ trong dữ liệu về bệnh tim mạcht.figure(figsize=(8,8))
sns.heatmap(df.corr(),annot = True)

# Tạo một biểu đồ countplot để đếm số lượng quan sát cho mỗi giá trị của biến "Smoking".
sns.countplot(x="Smoking", hue="HeartDisease", data=df)
sns.countplot(x = "Smoking", hue= "HeartDisease",data = df)

"""# Preprocessing"""

data = df[df['HeartDisease']=='Yes']
data

# Đếm số lượng quan sát cho mỗi giá trị của biến 'Smoking' trong dữ liệu đã lọc
smoke = data['Smoking'].value_counts()
smoke

# Tạo biểu đồ pie chart để biểu diễn phần trăm số lượng người hút thuốc và không hút thuốc trong nhóm mắc bệnh tim mạch
labels = ["Không","Có"]
plt.figure(figsize = (6,6))
plt.pie(smoke,labels = labels,autopct='%2.2f%%',shadow=True)
plt.legend(title='Người hút thuốc',loc='lower right')
plt.show()

def bar_chart(feature):
  live = df [df['HeartDisease']=='No'][feature].value_counts()
  die = df[df['HeartDisease']=='Yes'][feature].value_counts()
  df1 = pd.DataFrame([live,die])
  df1.index = ['Song','Tu vong']
  df1.plot(kind='bar',figsize=(10,5))

# Vẽ biểu đồ bar chart để so sánh số lượng quan sát của feature giữa nhóm sống sót và nhóm tử vong
bar_chart('Smoking')

# Tạo biểu đồ phân phối (distribution plot) để hiển thị phân phối của chỉ số BMI
sns.displot(df['BMI'])

def kde(x):
    facet=sns.FacetGrid(df,hue="HeartDisease",aspect=4)
    # Ánh xạ hàm kdeplot của seaborn lên mỗi phần tử của lưới, mỗi phần tử biểu diễn mật độ phân phối của biến x
    facet.map(sns.kdeplot,x,shade=True)
    facet.set(xlim=(df[x].min(),df[x].max()))
    facet.add_legend()
    plt.show()

# Mật độ phân phối của chỉ số BMI được phân biệt theo trạng thái của bệnh tim mạch
kde('BMI')

"""# Tiền xử lý dữ liệu"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import r2_score,mean_absolute_error,accuracy_score
from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()
# Danh sách các biến cần chuyển đổi từ dạng phân loại sang dạng số nguyên
list=['HeartDisease','Smoking', 'AlcoholDrinking', 'Stroke','DiffWalking', 'Sex', 'AgeCategory',
       'Race', 'Diabetic', 'PhysicalActivity', 'GenHealth', 'Asthma', 'KidneyDisease', 'SkinCancer']
for i in list:
    df[i]=le.fit_transform(df[i])

df.head()

# Tách dataframe thành hai phần: x chứa tất cả các cột ngoại trừ 'HeartDisease', y chứa cột 'HeartDisease' (biến mục tiêu)
x=df.drop(columns=['HeartDisease'])
y=df['HeartDisease']
x.sample(10)

"""# Undersampling"""

from imblearn.under_sampling import NearMiss

# Sử dụng phương thức fit_resample để tái chọn mẫu dữ liệu với phương pháp NearMiss
# new_x chứa các mẫu dữ liệu được tái chọn
# new_y chứa nhãn tương ứng của các mẫu dữ liệu tái chọn
NearMiss_obj = NearMiss()
new_x , new_y = NearMiss_obj.fit_resample(x,y)
new_y

new_y.value_counts()

df2=pd.DataFrame(new_x)
df2.head()

df3=pd.DataFrame(new_y)
df3.head()

df4=pd.concat([df2,df3],axis=1)
df4

"""# Feature ranking"""

df4.nunique()

from sklearn.ensemble import ExtraTreesClassifier

extr = ExtraTreesClassifier()
extr.fit(new_x,new_y)

# Trích xuất độ quan trọng của các đặc trưng từ mô hình Extra Trees Classifier
feature_importance = extr.feature_importances_
feature_importance

"""Ở đây ta thêm một cột 'Gain_score': chứa thông tin về độ quan trọng của các đặc trưng được tính toán từ mô hình Extra Trees Classifier. Độ quan trọng của một đặc trưng đo lường mức đóng góp của đặc trưng đó vào quá trình dự đoán của mô hình."""

# Tạo một dataframe từ độ quan trọng của các đặc trưng, với tên cột là 'Gain_Score'
imp = pd.DataFrame(feature_importance, columns=['Gain_Score'])
imp.head(10)

new_x.head()

new_x.columns

cols = pd.DataFrame(new_x.columns, columns=['Feature_Names'])
cols.head(10)

gains = pd.concat([cols,imp],axis=1)
gains

newx = gains.nlargest(18,'Gain_Score')
newx

sns.barplot(x='Gain_Score',y='Feature_Names',data=newx)

features = pd.Series(extr.feature_importances_, index = x.columns)
plt.figure(figsize=(14,6))
features.nlargest(10).plot(kind='barh', color='g')

from sklearn.feature_selection import SelectKBest, f_classif, chi2, f_regression

model2 = SelectKBest(score_func=f_classif)
feature_score = model2.fit(new_x,new_y)
feature_score.scores_

cols = pd.DataFrame(feature_score.scores_ , columns=['Feature_Scores'])
cols

col2 = pd.DataFrame(new_x.columns, columns=['Feature_Names'])
col2.head()

scores = pd.concat([col2,cols],axis=1)
scores

new = scores.nlargest(18,'Feature_Scores')
new

# Tạo biểu đồ bar plot để hiển thị độ quan trọng của các đặc trưng từ mô hình Extra Trees Classifier
plt.figure(figsize=(15,10))
sns.barplot(x='Feature_Scores',y='Feature_Names',data=new)
plt.title('Xếp hạng tính năng bằng trình phân loại SelectKBest',fontsize=18)

"""# Phân tích thành phần chính"""

from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
import plotly.express as pl

"""# Principal Component Analysis (PCA)

Là một phương pháp giảm số chiều dữ liệu bằng cách tìm các hướng chính của biến động và chuyển đổi dữ liệu sang không gian mới sao cho giữ lại thông tin quan trọng nhất. Điều này giúp giảm kích thước của dữ liệu trong khi vẫn giữ được phần lớn thông tin quan trọng.
"""

mmx = MinMaxScaler()
scaled_x = mmx.fit_transform(new_x)
pca = PCA(n_components=3)
x_pca = pca.fit_transform(scaled_x)
x_pca

features = pd.DataFrame(x_pca, columns=['pca1','pca2','pca3'])
# Biến 'pca1', 'pca2', 'pca3' là ba trục của dữ liệu, và màu sắc của các điểm được xác định bởi giá trị của 'pca1'
pl.scatter_3d(features, x='pca1',y='pca2',z='pca3', color='pca1')

"""# Explore Data Analysis (EDA)"""

sns.countplot(x='Smoking',hue='HeartDisease',data=df4)

def KDE(x):
    facet=sns.FacetGrid(df4,hue="HeartDisease",aspect=4)
    # Ánh xạ hàm kdeplot của seaborn lên mỗi phần tử của lưới, biểu diễn mật độ phân phối của biến x
    facet.map(sns.kdeplot,x,shade=True)
    # Thiết lập giới hạn trục x dựa trên giá trị tối thiểu và tối đa của biến x trong dataframe df4
    facet.set(xlim=(df4[x].min(),df4[x].max()))
    facet.add_legend()
    plt.show()

# Mật độ của biến BMI phân biệt theo trạng thái của biến 'HeartDisease'
KDE('BMI')
# Mật độ của biến PhysicalHealth phân biệt theo trạng thái của biến 'HeartDisease'
KDE('PhysicalHealth')
# Mật độ của biến SleepTime phân biệt theo trạng thái của biến 'HeartDisease'
KDE('SleepTime')

df4.corr()

plt.figure(figsize=(16,12))
sns.heatmap(df4.corr(),annot=True)

"""# Training and Testing"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
import xgboost
from xgboost import XGBClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier

# Model 1
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
# Model 1

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

X_train,X_test,y_train,y_test=train_test_split(new_x,new_y,train_size=0.75,random_state=42)

X_test.head(50)

"""# Logistic Regression
  Là một thuật toán học máy được sử dụng cho các bài toán phân loại. Nó được sử dụng để dự đoán xác suất của một biến phụ thuộc (có hai hoặc nhiều hạng mục) dựa trên một hoặc nhiều biến độc lập.
"""

log = LogisticRegression()
log.fit(X_train, y_train)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu kiểm tra
log_pred = log.predict(X_test)
log_score = metrics.accuracy_score(y_test, log_pred)
print("Logistic Regression Accuracy on Test Data:", log_score)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu huấn luyện
train_log_pred = log.predict(X_train)
train_log_score = metrics.accuracy_score(y_train, train_log_pred)
print("Logistic Regression Accuracy on Train Data:", train_log_score)

print("Logistic Regression Report:", metrics.classification_report(y_test, log_pred))

log_cm = metrics.confusion_matrix(y_test, log_pred)
plt.figure(figsize=(12, 12))
ax = sns.heatmap(log_cm, annot=True, fmt=".3f", linewidths=0.5, square=True, cmap="Oranges")
ax.set_ylabel("Actual label")
ax.set_xlabel("Predicted label")
title = "Logistic Regression Accuracy Score: {0}".format(log_score)
plt.title(title, size=15)

"""# Decision Tree Classification
Là một thuật toán học máy được sử dụng trong bài toán phân loại. Thuật toán này hoạt động dựa trên việc xây dựng một cây quyết định từ dữ liệu huấn luyện, trong đó mỗi nút trong cây đại diện cho một biến độc lập, mỗi nhánh là một quyết định dựa trên giá trị của biến đó, và mỗi lá là một lớp hoặc giá trị dự đoán.
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics

clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu kiểm tra
clf_pred = clf.predict(X_test)
clf_score = metrics.accuracy_score(y_test, clf_pred)
print("Decision Tree Classifier Accuracy on Test Data:", clf_score)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu huan luyen
train_clf_pred = clf.predict(X_train)
train_clf_score = metrics.accuracy_score(y_train, train_clf_pred)
print("Decision Tree Classifier Accuracy on Train Data:", train_clf_score)

print("Decision Tree Classifier Report:", metrics.classification_report(y_test, clf_pred))

clf_cm = metrics.confusion_matrix(y_test, clf_pred)
plt.figure(figsize=(12, 12))
ax = sns.heatmap(clf_cm, annot=True, fmt=".3f", linewidths=0.5, square=True, cmap="Purples")
ax.set_ylabel("Actual label")
ax.set_xlabel("Predicted label")
title = "Decision Tree Classifier Accuracy Score: {0}".format(clf_score)
plt.title(title, size=15)

"""# XGBoost Classification"""

import xgboost as xgb
from xgboost import XGBClassifier
from sklearn import metrics

xgb = XGBClassifier()
xgb.fit(X_train, y_train)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu kiểm tra
xgb_pred = xgb.predict(X_test)
xgb_score = metrics.accuracy_score(y_test, xgb_pred)
print("XGBoost Classifier Accuracy on Test Data:", xgb_score)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu huan luyen
train_xgb_pred = xgb.predict(X_train)
train_xgb_score = metrics.accuracy_score(y_train, train_xgb_pred)
print("XGBoost Classifier Accuracy on Train Data:", train_xgb_score)
print("XGBoost Classifier Report:", metrics.classification_report(y_test, xgb_pred))

xgb_cm = metrics.confusion_matrix(y_test, xgb_pred)
plt.figure(figsize=(12, 12))
ax = sns.heatmap(xgb_cm, annot=True, fmt=".3f", linewidths=0.5, square=True, cmap="Greys")
ax.set_ylabel("Actual label")
ax.set_xlabel("Predicted label")
title = "XGBoost Classifier Accuracy Score: {0}".format(xgb_score)
plt.title(title, size=15)

"""# Adaboost Classification
Là một thuật toán học máy được sử dụng trong bài toán phân loại. Thuật toán này hoạt động bằng cách xây dựng một chuỗi các mô hình phân loại yếu (weak learners), sau đó kết hợp chúng lại để tạo ra một mô hình phân loại mạnh (strong learner).
"""

from sklearn.ensemble import AdaBoostClassifier
from sklearn import metrics

ada = AdaBoostClassifier()
ada.fit(X_train, y_train)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu kiểm tra
ada_pred = ada.predict(X_test)
ada_score = metrics.accuracy_score(y_test, ada_pred)
print("Adaboost Classifier Accuracy on Test Data:", ada_score)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu huan luyen
train_ada_pred = ada.predict(X_train)
train_ada_score = metrics.accuracy_score(y_train, train_ada_pred)
print("Adaboost Classifier Accuracy on Train Data:", train_ada_score)

print("Adaboost Classifier Report:", metrics.classification_report(y_test, ada_pred))

ada_cm = metrics.confusion_matrix(y_test, ada_pred)
plt.figure(figsize=(12, 12))
ax = sns.heatmap(ada_cm, annot=True, fmt=".3f", linewidths=0.5, square=True, cmap="Blues")
ax.set_ylabel("Actual label")
ax.set_xlabel("Predicted label")
title = "Adaboost Classifier Accuracy Score: {0}".format(ada_score)
plt.title(title, size=15)

"""# K Nearest Neighbour Classification:"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
import time
from datetime import timedelta

# start_knn = time.time()
# knn_scores = []

# for i in range(1, 12):
#     knc = KNeighborsClassifier(i)
#     knn_pred = knc.fit(X_train, y_train).predict(X_test)
#     knn_scores.append(metrics.accuracy_score(y_test, knn_pred))

# max_knn_score = max(knn_scores)
# knn_score_ind = [i for i, v in enumerate(knn_scores) if v == max_knn_score]
# end_knn = time.time()
# times_knn = timedelta(seconds=round(end_knn - start_knn, 4)).total_seconds()

# print('Time', times_knn)

# knn_score = max_knn_score
# accuracies_max_knn = knn_score
# print("Accuracy", accuracies_max_knn)
# print("Report", metrics.classification_report(y_test, knn_pred))

knc = KNeighborsClassifier()
knc.fit(X_train, y_train)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu kiểm tra
knc_pred = knc.predict(X_test)
knc_score = metrics.accuracy_score(y_test, knc_pred)
print("KNearest Classifier Accuracy on Test Data:", knc_score)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu huan luyen
train_knc_pred = knc.predict(X_train)
train_knc_score = metrics.accuracy_score(y_train, train_knc_pred)
print("KNearest Classifier Accuracy on Train Data:", train_knc_score)

print("KMearest Classifier Report:", metrics.classification_report(y_test, knc_pred))

knn_cm = metrics.confusion_matrix(y_test, knc_pred)
plt.figure(figsize=(12, 12))
ax = sns.heatmap(knn_cm, annot=True, fmt=".3f", linewidths=0.5, square=True, cmap="Reds")
ax.set_ylabel("Actual label")
ax.set_xlabel("Predicted label")
title = "K Nearest Neighbour Classification Accuracy Score: {0}".format(knc_score)
plt.title(title, size=15)

"""# Support Vector Machine Classification:"""

from sklearn.svm import SVC
from sklearn import metrics

svm = SVC(kernel='linear')
svm.fit(X_train, y_train)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu kiểm tra
svm_pred = svm.predict(X_test)
svm_score = metrics.accuracy_score(y_test, svm_pred)
print("Support Vector Machine Classification Accuracy on Test Data:", svm_score)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu huan luyen
train_svm_pred = svm.predict(X_train)
train_svm_score = metrics.accuracy_score(y_train, train_svm_pred)
print("Support Vector Machine Classification Accuracy on Train Data:", train_svm_score)

print("Support Vector Machine Classification Report:", metrics.classification_report(y_test, svm_pred))

svm_cm = metrics.confusion_matrix(y_test, svm_pred)
plt.figure(figsize=(12, 12))
ax = sns.heatmap(svm_cm, annot=True, fmt=".3f", linewidths=0.5, square=True, cmap="Greens")
ax.set_ylabel("Actual label")
ax.set_xlabel("Predicted label")
title = "Support Vector Machine Classification Accuracy Score: {0}".format(svm_score)
plt.title(title, size=15)

"""# Random Forest Classification:"""

from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics

rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu kiểm tra
rfc_pred = rfc.predict(X_test)
rfc_score = metrics.accuracy_score(y_test, rfc_pred)
print("Random Forest Classification Accuracy on Test Data:", rfc_score)

# Tính toán độ chính xác của mô hình dự đoán trên dữ liệu huan luyen
train_rfc_pred = rfc.predict(X_train)
train_rfc_score = metrics.accuracy_score(y_train, train_rfc_pred)
print("Random Forest Classification Accuracy on Train Data:", train_rfc_score)

print("Random Forest Classification Report:", metrics.classification_report(y_test, rfc_pred))

rfc_cm = metrics.confusion_matrix(y_test, rfc_pred)
plt.figure(figsize=(12, 12))
ax = sns.heatmap(rfc_cm, annot=True, fmt=".3f", linewidths=0.5, square=True, cmap="Purples")
ax.set_ylabel("Actual label")
ax.set_xlabel("Predicted label")
title = "Random Forest Classification Accuracy Score: {0}".format(rfc_score)
plt.title(title, size=15)

plt.figure(figsize=(10, 6))
plt.xlabel('Algorithms')
plt.ylabel('Accuracies')
plt.title("Accuracies of all Algorithms on Test data")
sns.barplot(x=['LOG', 'CLF', 'XGB', 'ADA', 'KNC', 'SVM', 'RFC'], y=[log_score, clf_score, xgb_score, ada_score, knc_score, svm_score, rfc_score])
# Adding numbers above each bar
for i, score in enumerate([log_score, clf_score, xgb_score, ada_score, knc_score, svm_score, rfc_score]):
    plt.text(i, score, f'{score:.5f}', ha='center', va='bottom')
plt.show()

import pandas as pd

# Dữ liệu test thử

check_acc = {
    'BMI': 16.6,
    'Smoking': 1,
    'AlcoholDrinking': 0,
    'Stroke': 0,
    'PhysicalHealth': 3,
    'MentalHealth': 30,
    'DiffWalking': 0,
    'Sex': 1,
    'AgeCategory': 8,
    'Race': 6,
    'Diabetic': 1,
    'PhysicalActivity': 1,
    'GenHealth': 5,
    'SleepTime': 5,
    'Asthma': 1,
    'KidneyDisease': 0,
    'SkinCancer': 1,
}

df = pd.DataFrame(check_acc, index=[0])

# đưa dữa liệu cho mô hình XGb dự đoán
test_prediction = xgb.predict(df)  # Pass the DataFrame to predict
print(test_prediction)

"""# GUI"""

df4.head()

!pip install gradio
import gradio as gr

def heart(BMI, Smoking, AlcoholDrinking, Stroke, PhysicalHealth, MentalHealth, DiffWalking, Sex, AgeCategory, Race, Diabetic, PhysicalActivity, GenHealth, SleepTime, Asthma, KidneyDisease, SkinCancer):
    HeartDisease = rfc.predict([[BMI, Smoking, AlcoholDrinking, Stroke, PhysicalHealth, MentalHealth, DiffWalking, Sex, AgeCategory, Race, Diabetic, PhysicalActivity, GenHealth, SleepTime, Asthma, KidneyDisease, SkinCancer]])

    if HeartDisease == 0:
        return "Bạn không bị bệnh tim"
    elif HeartDisease == 1:
        return "Bạn có nguy cơ bị bệnh tim"
    else:
        return "Kết quả không xác định"

heart(26.54,0,0,0,0,0,0,1,6,5,0,1,0,7,0,0,0)

interface = gr.Interface(
  fn = heart, #function = heart
  inputs = ['number','number','number','number','number','number','number','number','number',
            'number','number','number','number','number','number','number','number'],
  outputs = ['text']
)
interface.launch()